{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UHH-LT at SemEval-2020 Task 12: Fine-Tuning of Pre-Trained Transformer Networks for Offensive Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Installation of requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tensorboardX import SummaryWriter\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "# Use this code when on GPU\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOT': 9460, 'OFF': 4640})\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "import datasets as ds\n",
    "#For Task A\n",
    "dataset = ds.OffensEvalData2020A(path=\"datasets/OffensEval20\", n_max=-1)\n",
    "s_train, s_test = dataset.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task A Labels\n",
    "id2label = {0:'NOT', 1:'OFF'}\n",
    "label2id = {'NOT':0, 'OFF':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_n = -1\n",
    "X = []\n",
    "for i, t in enumerate(s_train.texts):\n",
    "    if i == dev_n:\n",
    "        break\n",
    "    X.append((t, s_train.labels[i]))\n",
    "X_test = []\n",
    "for i, t in enumerate(s_test.texts):\n",
    "    X_test.append((t, s_test.ids[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "X_dev = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/srv/home/8vijayak/FINAL_uhhlt-offenseval2020/utils.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "#importlib.reload(utils)\n",
    "import utils\n",
    "convert_examples_to_features = utils.convert_examples_to_features\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "import random\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
    "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                                  AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer,\n",
    "                                  T5Config, T5Tokenizer,\n",
    "                                  XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer)\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from utils_classification import (convert_examples_to_features, output_modes, processors)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Select the model by changing the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for the best performing model Albert\n",
    "dict_model_names = {1: 'albert-base-v1',\n",
    "                    2: 'albert-large-v1',\n",
    "                    3: 'albert-xlarge-v1',\n",
    "                    4: 'albert-xxlarge-v1', \n",
    "                    \n",
    "                    5: 'albert-base-v2', \n",
    "                    6: 'albert-large-v2', \n",
    "                    7: 'albert-xlarge-v2', \n",
    "                    8: 'albert-xxlarge-v2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: oe2020-albert-A/\n",
      "Model Name: albert-base-v1\n",
      "Output Dir: oe2020-albert-A/oe2020_A/albert-base-v1/\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'data_dir': 'data/',\n",
    "    'model_type':  'albert',\n",
    "    'model_name': str(dict_model_names[1]), #As per the required model, change the index\n",
    "    #'task_name': 'offensiveA',\n",
    "    'task_name': 'oe2020_A',\n",
    "    'output_dir': 'oe2020-albert-A/',\n",
    "    'cache_dir': 'cache/',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'fp16': False,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'max_seq_length': 128,\n",
    "    'output_mode': 'classification',\n",
    "    'train_batch_size': 4,\n",
    "    'eval_batch_size': 4,\n",
    "\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 6,\n",
    "    'weight_decay': 0,\n",
    "    'learning_rate': 5e-6,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 0,\n",
    "    'max_grad_norm': 1.0,\n",
    "\n",
    "\n",
    "    'logging_steps': 0,\n",
    "    'evaluate_during_training': True,\n",
    "    'save_steps': 1000,\n",
    "    'eval_all_checkpoints': True,\n",
    "    'overwrite_output_dir': False,\n",
    "    'reprocess_input_data': True,\n",
    "    'notes': 'Offensive language classification task'\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Output dir: \" + str(args['output_dir']))\n",
    "print(\"Model Name: \" + str(args['model_name']))\n",
    "args['output_dir'] = args['output_dir']+args['task_name']+\"/\"+args['model_name']+\"/\"\n",
    "print(\"Output Dir: \" + str(args['output_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
    "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
    "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),\n",
    "    'albert': (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer),\n",
    "    't5': (T5Config, T5Tokenizer),\n",
    "    'xlmroberta': (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer)\n",
    "}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(args['model_name'], num_labels=2, finetuning_task=args['task_name']) #Task A\n",
    "tokenizer = tokenizer_class.from_pretrained((args['model_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args['task_name']\n",
    "processor = processors[task](X_train, X_dev)\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels is: 2\n",
      "The labels for Task A are: ['NOT', 'OFF']\n"
     ]
    }
   ],
   "source": [
    "#For Task A: ['NOT', 'OFF']\n",
    "print(\"Number of labels is: \" + str(num_labels))\n",
    "print(\"The labels for Task A are: \" + str(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load model and train them on the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(args['model_name'], num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, evaluate=False):\n",
    "    processor = processors[task](X_train, X_dev)\n",
    "    output_mode = args['output_mode']\n",
    "    \n",
    "    mode = 'dev' if evaluate else 'train'\n",
    "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n",
    "    \n",
    "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "               \n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
    "        label_list = processor.get_labels()\n",
    "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
    "        \n",
    "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
    "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
    "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0)\n",
    "        \n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "        \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset\n",
    "\n",
    "                                        \n",
    "from pprint import pprint\n",
    "                                        \n",
    "def train(train_dataset, model, tokenizer):\n",
    "    tb_writer = SummaryWriter()\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n",
    "    \n",
    "    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'], num_training_steps=t_total)\n",
    "    \n",
    "    if args['fp16']:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n",
    "        \n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n",
    "    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n",
    "    \n",
    "    epoch_i = 0\n",
    "    max_metric = 0\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        epoch_i += 1\n",
    "        print(\"Training Epoch %d\" % epoch_i)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "            if args['gradient_accumulation_steps'] > 1:\n",
    "                loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "            if args['fp16']:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n",
    "                \n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n",
    "                    # Log metrics\n",
    "                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results, _ = evaluate(model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args['logging_steps'], global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "        # Save model checkpoint\n",
    "        output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(epoch_i))\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(output_dir)\n",
    "        logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mismatched(labels, preds):\n",
    "    mismatched = labels != preds\n",
    "    examples = processor.get_dev_examples(args['data_dir'])\n",
    "    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def get_eval_report(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        #These are uncommented in Seid's code\n",
    "         \"tp\": tp,\n",
    "         \"tn\": tn,\n",
    "         \"fp\": fp,\n",
    "         \"fn\": fn,\n",
    "        \"acc\" : acc,\n",
    "        \"f1\" : f1\n",
    "    }, get_mismatched(labels, preds)\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return get_eval_report(labels, preds)\n",
    "\n",
    "def evaluate(model, tokenizer, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args['output_dir']\n",
    "\n",
    "    results = {}\n",
    "    EVAL_TASK = args['task_name']\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args['output_mode'] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args['output_mode'] == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    # print(preds)\n",
    "    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n",
    "    results.update(result) \n",
    "\n",
    "    return results, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args['do_train']:\n",
    "    train_dataset = load_and_cache_examples(task, tokenizer)\n",
    "    global_step, tr_loss = train(train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Save the pre-trained check points under the respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this only for training\n",
    "if args['do_train']:\n",
    "    if not os.path.exists(args['output_dir']):\n",
    "            os.makedirs(args['output_dir'])\n",
    "    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n",
    "    \n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained(args['output_dir'])\n",
    "    tokenizer.save_pretrained(args['output_dir'])\n",
    "    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Evaluate the pre-trained model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_prediction(task, X_predict, tokenizer):\n",
    "    processor = processors[task](X_predict, None)\n",
    "    output_mode = args['output_mode']\n",
    "    examples = processor.get_train_examples(None)\n",
    "    features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
    "        cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
    "        cls_token=tokenizer.cls_token,\n",
    "        sep_token=tokenizer.sep_token,\n",
    "        cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
    "        pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
    "        pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(sentences):\n",
    "    X = [(s, 'OFF') for s in sentences]\n",
    "    predict_dataset = prepare_prediction(task, X, tokenizer)\n",
    "    eval_sampler = SequentialSampler(predict_dataset)\n",
    "    eval_dataloader = DataLoader(predict_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "    prefix = \"\"\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(predict_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n",
    "                      'labels':         batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    probabilities = sm(torch.from_numpy(preds)).numpy()\n",
    "    # relevancy_scores = probabilities[:,1]\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run this for evaluation\n",
    "test_sentences, test_ids = zip(*X_test)\n",
    "fold_model_dirs = list(os.path.dirname(c) for c in sorted(glob.glob(args['output_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n",
    "emsemble_preds = np.empty((len(test_sentences), len(fold_model_dirs)))\n",
    "for i, fold_dir in enumerate(fold_model_dirs):\n",
    "    print(fold_dir)\n",
    "    model = model_class.from_pretrained(fold_dir)\n",
    "    model.to(device)\n",
    "    prob_scores = predict_sentences(test_sentences)\n",
    "    predicted_labels = [a.argmax() for a in prob_scores]\n",
    "    emsemble_preds[:, i] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this if the previous code is snippet is run. This saves the ensemble predictions to the file\n",
    "pickle.dump(emsemble_preds, file=open(os.path.join(args['output_dir'], \"testset_predictions.p\"), \"wb\"))\n",
    "emsemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_preds = emsemble_preds.mean(axis=1)\n",
    "mean_preds.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the Predictions and Majority Vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the model are available, run only this section to ensemble the models and generated the majority vote as mentioned in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_report2(labels, preds):\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # macro\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    p = precision_score(labels, preds, average='macro')\n",
    "    r = recall_score(labels, preds, average='macro')\n",
    "    \n",
    "    # not\n",
    "    f1_0 = f1_score(labels, preds, average='binary', pos_label=0)\n",
    "    p_0 = precision_score(labels, preds, average='binary', pos_label=0)\n",
    "    r_0 = recall_score(labels, preds, average='binary', pos_label=0)\n",
    "    \n",
    "    # off\n",
    "    f1_1 = f1_score(labels, preds, average='binary', pos_label=1)\n",
    "    p_1 = precision_score(labels, preds, average='binary', pos_label=1)\n",
    "    r_1 = recall_score(labels, preds, average='binary', pos_label=1)\n",
    "    \n",
    "    return {\n",
    "        \"mcc\": mcc,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"acc\" : acc,\n",
    "        \"f1\" : f1,\n",
    "        \"precision\" : p,\n",
    "        \"recall\" : r,\n",
    "        \"p_not\" : p_0,\n",
    "        \"r_not\" : r_0,\n",
    "        \"f1_not\" : f1_0,\n",
    "        \"p_off\" : p_1,\n",
    "        \"r_off\" : r_1,\n",
    "        \"f1_off\" : f1_1\n",
    "    }, get_mismatched(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Load this pre-trained models and ensemble them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "oe2020-albert-A/oe2020_A/albert-xxlarge-v1/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-xlarge-v2/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-base-v2/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-xlarge-v1/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-large-v1/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-large-v2/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-xxlarge-v2/testset_predictions.p\n",
      "oe2020-albert-A/oe2020_A/albert-base-v1/testset_predictions.p\n"
     ]
    }
   ],
   "source": [
    "# Loading all files in the path with predictions\n",
    "import os\n",
    "path = 'oe2020-albert-A/oe2020_A/'\n",
    "files = []\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.p' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "print(len(files))\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_ids = zip(*X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3887"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Albert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Using the majority vote option, the predictions are computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "preds = []\n",
    "for f in files:\n",
    "    if 'albert-xlarge-v2' in f:\n",
    "        preds.append(pickle.load(open( f, \"rb\" )))\n",
    "    if 'albert-xlarge-v1' in f:\n",
    "        preds.append(pickle.load(open( f, \"rb\" )))\n",
    "    if 'albert-xxlarge-v2' in f:\n",
    "        preds.append(pickle.load(open( f, \"rb\" )))\n",
    "    if 'albert-xxlarge-v1' in f:\n",
    "        preds.append(pickle.load(open( f, \"rb\" )))\n",
    "        \n",
    "import numpy as np\n",
    "merged_preds = np.concatenate(preds, axis = 1)\n",
    "from collections import Counter\n",
    "majority_preds = []\n",
    "for i in range(merged_preds.shape[0]):\n",
    "    majority_preds.append(Counter(merged_preds[i].astype(int)).most_common(1)[0][0])\n",
    "mean_preds = merged_preds.mean(axis=1)\n",
    "final_preds = majority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = []\n",
    "for i, t in enumerate(s_test.texts):\n",
    "      lables.append(label2id[s_test.labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: The Precision, Recall and F1 scores for labels {NOT, OFF} and overall Macro F1 and Accuracy are determined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code evaluated the predictions and calculates Precision, Recall and F1 scores for NOT and OFF labels.\n",
    "# Also the Macro F1 and Accuracy for the entire ensemble\n",
    "result, wrong = get_eval_report2(np.array(lables), final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT:\tP: 98.299\tR: 92.63\tF1: 95.38\n",
      "OFF:\tP: 83.33\tR: 95.83\tF1: 89.15\n"
     ]
    }
   ],
   "source": [
    "print(\"NOT:\" + \"\\t\" +  \"P: %s\" %(str(round(result[\"p_not\"]*100, 3))) + \"\\t\" +  \"R: %s\" %(str(round(result[\"r_not\"]*100, 2))) + \"\\t\" +  \"F1: %s\" %(str(round(result[\"f1_not\"]*100, 2))))\n",
    "print(\"OFF:\" + \"\\t\" +  \"P: %s\" %(str(round(result[\"p_off\"]*100, 2))) + \"\\t\" +  \"R: %s\" %(str(round(result[\"r_off\"]*100, 2))) + \"\\t\" +  \"F1: %s\" %(str(round(result[\"f1_off\"]*100, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 92.26\tACC: 93.52\n"
     ]
    }
   ],
   "source": [
    "print(\"F1: %s\" %(str(round(result[\"f1\"]*100, 2))) + \"\\t\" + \"ACC: %s\" %(str(round(result[\"acc\"]*100, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2600  207]\n",
      " [  45 1035]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(np.array(lables), final_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2600  207]\n",
      " [  45 1035]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(np.array(lables), final_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class IdentityEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.is_fitted_ = True\n",
    "        self.classes_ = [0, 1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X\n",
    "estim = IdentityEstimator()\n",
    "\n",
    "def plot_conf_mat(true_labels, predicted_labels, label_names, plot_title):\n",
    "    matplotlib.rcParams.update({'font.size': 20})\n",
    "    disp = sklm.plot_confusion_matrix(estim, np.array(predicted_labels), true_labels, \n",
    "                                      cmap=plt.cm.Blues, values_format = '.5g',\n",
    "                                      display_labels=label_names)\n",
    "    disp.ax_.set_title(plot_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_mat(np.array(lables), final_preds, ['NOT', 'OFF'], 'Task A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
